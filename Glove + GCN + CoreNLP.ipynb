{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove + GCN + CoreNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMt4TgKl51Y7oWbpDL1uBme",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fakabbir/AI-Playbook/blob/master/Glove%20%2B%20GCN%20%2B%20CoreNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1D9lW5lOl-k",
        "outputId": "258b0c9e-6769-4bcb-d87a-b85036d00277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-20 08:34:22--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-04-20 08:34:22--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-04-20 08:34:23--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.82MB/s    in 2m 42s  \n",
            "\n",
            "2022-04-20 08:37:05 (5.09 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading the vector file\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking cuda version\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0iWfGuGSxlT",
        "outputId": "d4815a5c-b18b-4362-80df-4de78d6ca5ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the right cude version pytorch\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu111"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHbx51NmSxoO",
        "outputId": "62462bfb-d0db-4706-a068-a0fbc5900678"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu111\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking files\n",
        "!ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HmOc3pnTDHb",
        "outputId": "ab2f06a6-b2c5-491b-ab36-6ca15f9f1b2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".   .config\t       glove.6B.200d.txt  glove.6B.50d.txt  sample_data\n",
            "..  glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into vector space\n",
        "import os\n",
        "import numpy as np\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "V2Nw6IYeSxrm",
        "outputId": "9c382a3f-bb72-4386-ae0b-4f6bafc31457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index['dancing']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SqsK5bjQFnY",
        "outputId": "38e94228-ad57-4fa7-bc17-01ec3b122179"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.8927e-01,  1.3668e-01,  1.0018e-01,  8.6889e-02, -3.7379e-04,\n",
              "        1.2549e+00, -3.0605e-01,  8.2326e-01, -3.1645e-01, -2.6105e-01,\n",
              "        8.8670e-02, -3.7473e-01,  2.3649e-01,  1.4771e-01, -3.5600e-01,\n",
              "        1.3845e-01, -1.6199e-01,  4.6586e-01,  2.3392e-01, -3.7496e-01,\n",
              "       -1.4306e-01,  1.6502e-01,  7.2604e-01, -5.7993e-01,  2.1166e-01,\n",
              "        6.6273e-01, -7.3482e-01, -2.5190e-01,  4.5720e-01, -4.2118e-02,\n",
              "       -8.2452e-01, -2.2596e-01,  4.6759e-01, -1.9811e-01,  5.5191e-01,\n",
              "       -4.3812e-01, -4.5375e-02,  2.4324e-01, -2.0800e-01, -6.9571e-01,\n",
              "        1.8216e-01,  3.7280e-01, -6.7986e-01,  1.0618e-01,  2.1276e-02,\n",
              "       -2.1635e-01, -1.1486e+00, -8.0755e-03,  1.2753e-01, -6.2336e-01,\n",
              "       -6.1599e-01, -3.0707e-01,  9.8371e-03,  9.4887e-01, -2.1619e-01,\n",
              "       -2.0712e+00, -1.1367e-01,  7.9654e-01,  2.3070e-01,  7.2508e-01,\n",
              "        3.6047e-01,  1.2606e+00,  6.0255e-03,  1.5010e-01, -2.1836e-01,\n",
              "        7.9186e-01,  6.6293e-01, -7.5083e-01,  1.0351e-01, -2.0340e-01,\n",
              "       -5.4170e-01, -5.3069e-01, -1.8099e-01,  4.2384e-01, -3.1235e-01,\n",
              "        4.0674e-01, -5.0875e-02, -1.5930e-01,  5.2546e-01, -7.2384e-01,\n",
              "       -5.4292e-02, -7.4064e-01,  7.7304e-01, -1.7588e-01, -8.9817e-01,\n",
              "       -5.3978e-01, -7.5861e-01, -9.2799e-02,  1.4151e-01, -3.2187e-01,\n",
              "       -3.1179e-01, -5.4399e-01, -2.2811e-01,  3.2990e-01, -4.5099e-01,\n",
              "       -1.1351e+00, -1.5762e+00, -1.8626e-01,  6.4248e-01,  7.1585e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "lLyhn0UZQNeO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare embedding matrix\n",
        "num_tokens = 1 + len(embeddings_index)\n",
        "embedding_dim = len(embeddings_index['the'])\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "\n",
        "embedding_matrix_idx = {}\n",
        "for idx,word in enumerate(embeddings_index):\n",
        "    embedding_matrix[1+idx] = embeddings_index[word]\n",
        "    embedding_matrix_idx[word] = 1 +idx\n",
        "\n",
        "weight = torch.FloatTensor(embedding_matrix)\n",
        "embedding = nn.Embedding.from_pretrained(weight)"
      ],
      "metadata": {
        "id": "biIkNZr9RV8i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "            'hidden_size': 192,\n",
        "            'input_size': embedding_dim,\n",
        "            'bias': True,\n",
        "            'dropout': 0.2,\n",
        "            'bidirectional': True }\n",
        "\n",
        "model = nn.LSTM(**params)\n",
        "fc = nn.Linear(192, 2)"
      ],
      "metadata": {
        "id": "TsYNoyCPL1eL",
        "outputId": "389f9c59-27c7-4bf5-ccfb-ba99257c8ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, 150)\n",
        "        self.fc2 = nn.Linear(150, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #text = [sent len, batch size]\n",
        "        idx = embedding_matrix_idx[text]\n",
        "        embedded = torch.unsqueeze(torch.unsqueeze(weight[idx], dim=0), dim = 0)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        # assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "\n",
        "        return self.fc2(self.fc1(hidden.squeeze(0)))\n",
        "\n",
        "rnn = RNN(1,100,192,2)\n",
        "rnn(\"cat\")"
      ],
      "metadata": {
        "id": "6itykECpNRtN",
        "outputId": "cd900267-de70-42c8-ca0c-2e454b775cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0707, -0.1051]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given a sentance convert it into its idx form\n",
        "\n",
        "x = \"This is a cool thing\"\n",
        "\n",
        "def pipeline(x):\n",
        "    x = x.lower()\n",
        "    x = x.split(\" \")\n",
        "    vector = []\n",
        "    for i in x:\n",
        "      if i in embedding_matrix_idx:\n",
        "        vector.append(embedding_matrix_idx[i])\n",
        "      else:\n",
        "        vector.append(0)\n",
        "\n",
        "    return vector\n",
        "pipeline(x)\n"
      ],
      "metadata": {
        "id": "nbQbdL05Pvrs",
        "outputId": "1f720682-0755-4984-8bef-d9bb687dea05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[38, 15, 8, 3452, 874]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, 150)\n",
        "        self.fc2 = nn.Linear(150, output_dim)\n",
        "        # self.sig = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #text = [sent len, batch size]\n",
        "        text = pipeline(text)\n",
        "        n = len(text)\n",
        "        text = torch.tensor(text)\n",
        "        embedded =  torch.unsqueeze(self.embedding(text), dim = 0)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        \n",
        "        hidden = torch.zeros(1,1,100)\n",
        "        for i in embedded:\n",
        "          output, hidden = self.rnn(hidden)\n",
        "\n",
        "        # opt,hdn = self.rnn(embedded.view(len(n), 1, -1))\n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        # assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "\n",
        "        out =  self.fc2(self.fc1(hidden.squeeze(0)))\n",
        "        # sigmoid function\n",
        "        # sig_out = self.sig(out)\n",
        "\n",
        "        return torch.argmax(out)\n",
        "\n",
        "rnn = RNN(1,100,192,2)\n",
        "rnn(\"run run run please follow\")"
      ],
      "metadata": {
        "id": "lYVKnIhgT3K2",
        "outputId": "0c2de4b9-ef0a-4434-bc23-f319ff321b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(rnn.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "2NJEKuVxUXFz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = [\n",
        "    # Tags are: DET - determiner; NN - noun; V - verb\n",
        "    # For example, the word \"The\" is a determiner\n",
        "    (\"The dog ate the apple\", 1),\n",
        "    (\"Everybody read that book\", 0)\n",
        "]"
      ],
      "metadata": {
        "id": "J-pssOZPKEbs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    inputs = training_data[0][0]\n",
        "    print(inputs)\n",
        "    tag_scores = rnn(inputs)\n",
        "    print(tag_scores)"
      ],
      "metadata": {
        "id": "4NuOmgsNKWvO",
        "outputId": "6a9d0103-1a7b-4003-e5e0-788bb88f92ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dog ate the apple\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w42jxWb3KoSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}